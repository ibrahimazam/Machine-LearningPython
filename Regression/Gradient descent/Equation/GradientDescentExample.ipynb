{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<span style=\"color:Yellow;\">\n",
    "\n",
    "### Gradient Descent\n",
    "\n",
    "<span style=\"color:MediumOrchid;\">\n",
    "\n",
    "- While we looking for the value of Theta 0 and Theta 1 which is going to minimize the The J Valuse which is the cost function, we will assume some value of Theta. then we will gradually minimize the values until we get the minimum value of J -\n",
    "\n",
    "- First of all := mean overwrite the left value with th right value. \n",
    "- a is coffecint when is increase the steps will be faster mostly the less accurcy. and when decrease the steps will slower but mor accurate. \n",
    "\n",
    "- The hypothesis function represents the equation of the line to be fitted. Here theta-0 and theta-1 represent the parameters of the regression line. In the line equation (y = mx + c), m is a slope and c is the y-intercept of the line. In the given equation, theta-0 is the y-intercept and theta-1 is the slope of the regression line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{red} \\alpha = $ $\\color{yellow} Decreasing\\ Rate\\ OR\\ learning\\ rate\\ (alpha)$\n",
    "\n",
    "$ \\color{red}:=$ $\\color{yellow} \\ mean\\ overwrite$\n",
    "\n",
    "$ \\color{red} m$ $\\color{yellow} = number\\ of \\ rows$\n",
    "\n",
    "$ \\color{red} h(x)$ $\\color{yellow} = the\\ predicted \\ value$\n",
    "\n",
    "$ \\color{red} y =$ $\\color{yellow} the\\ actual\\ value$\n",
    "\n",
    "$\\color{red} \\theta _{0},\\theta_{1}$ = Prarmeters\n",
    "\n",
    "$ \\color{red} \\theta _{0}$ $\\color{yellow}  := \\theta _{0} =\\alpha \\frac{1}{m} \\sum\\limits _{i=1} ^{m } (h _\\theta (x _{i}) -y _{i}) $ \n",
    "\n",
    "$ \\color{red} \\theta _{1}$ $\\color{yellow}   := \\theta _{1} =\\alpha \\frac{1}{m} \\sum\\limits _{i=1} ^{m } ((h _\\theta (x _{i}) -y _{i}) x _{i}$ \n",
    "\n",
    "$\\color{red} Hypothesis:$     $\\color{yellow} {h} _\\theta {(x)} = \\theta _{0} + \\theta _{1} x$\n",
    "\n",
    "$\\color{red} Definition:$ $\\color{yellow} \\theta _ 0 = y \\ intercept$\n",
    "\n",
    "$\\color{red} Definition:$ $\\color{yellow} \\theta _ 1 = b \\ slope $ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='images\\GradinetDescent2d.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='images\\GradinetDescent3d.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='images\\GradinetDescentGlobalAndLocal.png') \n",
    "\n",
    "# as we see a very simple curve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='images\\GradinetDescentLearningRate.png') \n",
    "\n",
    "# as we see a very simple two curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:MediumOrchid;\">\n",
    "\n",
    "### Correct: simultaneous update \n",
    "\n",
    "- both equation sholud walk in parllel together, and repeated together\n",
    "\n",
    "\n",
    "$\\color {red} \\partial = $ $\\color {yellow} Partial \\   Derivatives$\n",
    "\n",
    "$\\color {red} Correct:$  $\\color {yellow} simultaneous \\ update $\n",
    "\n",
    "$\\color {green} temp \\ 0 :=$ $\\color {yellow} \\theta _{0} - \\alpha \\frac{\\partial}{\\partial \\theta _{0}}J(\\theta _{0},\\theta_{1})$\n",
    "\n",
    "$\\color {green} temp \\ 1 :=$ $\\color {yellow} \\theta _{1} - \\alpha \\frac{\\partial}{\\partial \\theta _{0}}J(\\theta _{0},\\theta_{1})$\n",
    "\n",
    "$\\color {yellow} \\theta _{0}$ $\\color {green}:= temp0$\n",
    "\n",
    "$\\color {yellow} \\theta _{1}$ $\\color {green}:= temp0$\n",
    "\n",
    "\n",
    "$\\color {red} InCorrect:$  $\\color {red} simultaneous \\ update $\n",
    "\n",
    "$\\color {green} temp \\ 0 :=$ $\\color {yellow} \\theta _{0} - \\alpha \\frac{\\partial}{\\partial \\theta _{0}}J(\\theta _{0},\\theta_{1})$\n",
    "\n",
    "$\\color {yellow} \\theta _{0}$ $\\color {green}:= temp0$\n",
    "\n",
    "$\\color {green} temp \\ 1 :=$ $\\color {yellow} \\theta _{1} - \\alpha \\frac{\\partial}{\\partial \\theta _{0}}J(\\theta _{0},\\theta_{1})$\n",
    "\n",
    "$\\color {yellow} \\theta _{1}$ $\\color {green}:= temp0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    X1    Y\n",
      "0  100  135\n",
      "1   95  130\n",
      "2   90  110\n",
      "3   80   95\n",
      "4   80   90\n",
      "5   70   85\n",
      "6   70   80\n",
      "7   60   80\n"
     ]
    }
   ],
   "source": [
    "# in oreder to get best fit line we will assume thetas for some values for example Theta 0 = 1 Theta 1 = 3 \n",
    "# The Equation will be h(x) = 1 + 3x\n",
    "import pandas as pd\n",
    "# intialise data of lists.\n",
    "# Example \n",
    "data = {'X1':['100', '95', '90', '80','80','70','70','60'],\n",
    "        'Y':[135, 130, 110, 95,90,85,80,80]}\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "# Print the output.\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need of a Linear regression\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# Define the dataset\n",
    "x=  np.array([100,95,90,80,80,70,70,60])\n",
    "y = np.array([135,130,110,95,90,85,80,11])\n",
    "n = np.size(x)\n",
    "experience = x #Independent Variable.\n",
    "salary = y #Dependent Variable.\n",
    "# Plot the data points\n",
    "plt.style.use('dark_background')\n",
    "plt.scatter(x,y, color = 'red')\n",
    "plt.xlabel(\"Experience\")\n",
    "plt.ylabel(\"Salary\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis:     $\\color{red} {h} _\\theta {(x)} = \\theta _{0} + \\theta _{1} x$\n",
    "\n",
    "$\\color {Yellow} h(x) = 1 + 3 X$\n",
    "\n",
    "$\\color {Yellow} Theta \\ \\theta _{0}$ = 1\n",
    "\n",
    "$\\color {Yellow} Theta \\ \\theta _{1}$ = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate h(x)\n",
    "# in oreder to get best fit line we will assume thetas for some values for example Theta 0 = 1 Theta 1 = 3 \n",
    "# The Equation will be h(x) = 1 + 3x\n",
    "import pandas as pd\n",
    "# intialise data of lists.\n",
    "# Example \n",
    "data = {'X1':['100', '95', '90', '80','80','70','70','60'],\n",
    "        'Y':[300, 285, 270, 240,235,200,205,180],\n",
    "        'h(x)':[301,286,271,241,241,211,211,181] }\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "# Print the output.\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate h(x) -y\n",
    "# in oreder to get best fit line we will assume thetas for some values for example Theta 0 = 1 Theta 1 = 3 \n",
    "# The Equation will be h(x) = 1 + 3x\n",
    "import pandas as pd\n",
    "# intialise data of lists.\n",
    "# Example \n",
    "data = {'X1':['100', '95', '90', '80','80','70','70','60'],\n",
    "        'Y':[300, 285, 270, 240,235,200,205,180],\n",
    "        'h(x)':[301,286,271,241,241,211,211,181],\n",
    "         'h(x) -y':[1,1,1,1,6,11,6,1]}\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "# Print the output.\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\color{Red} Theta \\ 0 $ \n",
    "\n",
    "$ \\color{Yellow} \\theta _{0} := \\theta _{0} =\\alpha \\frac{1}{m} \\sum\\limits _{i=1} ^{m } (h _\\theta (x _{i}) -y _{i}) $ \n",
    "\n",
    "$\\color {yellow} \\theta _{0} $ = 1 \n",
    "\n",
    "$\\color {yellow} summation \\ of \\ difference  $ = 28\n",
    "\n",
    "$\\color {yellow} \\alpha$ = 0.002\n",
    "\n",
    "$\\color {yellow} m $ = 8\n",
    "\n",
    "### Theta 0 = 1 - ((0.0002 /8) * (28))\n",
    "### Theta 0 = 1 - 0.007 = 0.993\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate h(x) -y\n",
    "# in oreder to get best fit line we will assume thetas for some values for example Theta 0 = 1 Theta 1 = 3 \n",
    "# The Equation will be h(x) = 1 + 3x\n",
    "import pandas as pd\n",
    "# intialise data of lists.\n",
    "# Example \n",
    "data = {'X1':['100', '95', '90', '80','80','70','70','60'],\n",
    "        'Y':[135, 130, 110, 95,90,85,80,80],\n",
    "        'h(x)':[301,286,271,241,241,211,211,181],\n",
    "         'h(x) -y':[1,1,1,1,6,11,6,1],\n",
    "          '(h(x) -y)x':[100,95,90,80,480,770,420,60]}\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "# Print the output.\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\color{Red} Theta \\ 1 $ \n",
    "\n",
    "$ \\color{Yellow} \\theta _{1} := \\theta _{1} =\\alpha \\frac{1}{m} \\sum\\limits _{i=1} ^{m } ((h _\\theta (x _{i}) -y _{i}) x _{i} $ \n",
    "\n",
    "$\\color {yellow} \\theta _{1} $ = 3\n",
    "\n",
    "$\\color {yellow} summation \\ of \\ difference  $ = 2095\n",
    "\n",
    "$\\color {yellow} \\alpha$ = 0.002\n",
    "\n",
    "$\\color {yellow} m $ = 8\n",
    "\n",
    "### Theta 1 = 3 - ((0.0002 /8) * (2095))\n",
    "### Theta 1 = 3 - 0.052 = 2.48\n",
    "\n",
    "\n",
    "### Will will repeat until we get the optimal value of J\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated coefficients:\n",
      "theta_0 = 11.236363636363636 \n",
      "theta_1 = 1.1696969696969697\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.103\n"
     ]
    }
   ],
   "source": [
    "https://www.educative.io/edpresso/a-deep-dive-into-linear-regression-3-way-implementation\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def estimate_coef(x, y): \n",
    "    n = np.size(x) \n",
    "    m_x, m_y = np.mean(x), np.mean(y) \n",
    "\n",
    "    SS_xy = np.sum(y*x) - n*m_y*m_x \n",
    "    SS_xx = np.sum(x*x) - n*m_x*m_x \n",
    "\n",
    "    theta_1 = SS_xy / SS_xx \n",
    "    theta_0 = m_y - theta_1*m_x \n",
    "\n",
    "    return(theta_0, theta_1) \n",
    "\n",
    "def plot_regression_line(x, y, theta): \n",
    "\n",
    "    plt.scatter(x, y, color = \"b\",marker = \"o\", s = 30) \n",
    "    y_pred = theta[0] + theta[1]*x \n",
    "\n",
    "    plt.plot(x, y_pred, color = \"r\") \n",
    "\n",
    "    plt.xlabel('x') \n",
    "    plt.ylabel('y') \n",
    "    plt.show() \n",
    "\n",
    "\n",
    "x = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) \n",
    "y = np.array([11 ,13, 12, 15, 17, 18, 18, 19, 20, 22]) \n",
    "\n",
    "theta = estimate_coef(x, y) \n",
    "print(\"Estimated coefficients:\\ntheta_0 = {} \\ntheta_1 = {}\".format(theta[0], theta[1])) \n",
    "\n",
    "plot_regression_line(x, y, theta) \n",
    "\n",
    "print(round(theta[0]+ theta[1]*11,4))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9780809c1dcb5ebfb6c99d6eaff53e5915ef1e624894815a228c084387870e35"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
